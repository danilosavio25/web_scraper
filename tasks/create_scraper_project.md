<role>

Act as Python expert. Create a python project that can be used to scrape websites. 

</role>

<features>
- It receives a url as an argument and returns the html content of the page. 
- There should be a flag to enable or disable subpages scraping. 
- It should have the possibility of passing the url and the flag via terminal arguments.
- Create a visual status with the progress of the scraping and friendly messages.
- Scrapped pages should be casted to markdown format.
- Scrapped pages should be saved in a directory passed in params and should be Saved in "scraped_data/[site_name]/[page_name].md" by default if no directory is passed.
- Create the project in a virtual environment.
- Create a requirements.txt file with the project dependencies.
- Create a .gitignore file with the project dependencies.
- Create a README.md file with instructions on how to use the project.
</features>

<good_practices>
- Make it organized, clean and easy to use. 
- Use python good practices. 
</good_practices>